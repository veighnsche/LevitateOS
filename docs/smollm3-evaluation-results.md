# SmolLM3-3B Evaluation Results for LevitateOS Installer

**Date:** 2026-01-16
**Model:** SmolLM3-3B (base, no fine-tuning)
**Test Dataset:** 100 examples from `testing/test_dataset.jsonl`

## Summary

| Metric | Score |
|--------|-------|
| Overall Type Accuracy | 49% |
| Text Response Accuracy | 100% (49/49) |
| Command Type Accuracy | ~0% (0/51) |
| Command Exact Match | 0% |
| Command Partial Match | 100% |

## Key Findings

### What Works (No Training Needed)

1. **Tool call format is correct** - SmolLM3-3B properly outputs:
   ```xml
   <tool_call>
   {"name": "run_shell_command", "arguments": {"command": "..."}}
   </tool_call>
   ```

2. **Text responses work perfectly** - Greetings, questions, and conversational responses are handled correctly.

3. **Safety refusals work** - The model refuses dangerous commands like "delete everything" (verified in earlier manual testing).

### What Needs Training (LoRA Required)

1. **Wrong command selection** - When asked to "list disks", the model outputs `df -h` instead of `lsblk`. It knows to run a disk-related command but picks the wrong one.

2. **No contextual workflow understanding** - The installer expects:
   - User: "ola" (hello)
   - Assistant: "Ready to install?"
   - User: "sim" (yes)
   - **Expected:** `lsblk` (start by listing disks)
   - **Actual:** Text response describing installation steps

   The model doesn't understand that "yes" after a greeting means "start the installation workflow."

3. **Commands output as text** - Sometimes the model outputs commands in text format (`$ mkfs.ext4 /dev/vda1`) instead of using the tool call format.

## Detailed Failure Analysis

### Example: Confirmation Flow
```
User: "yes" (confirming partition plan)
Expected: sgdisk -Z /dev/vda && sgdisk -n 1:0:+512M -t 1:ef00 ...
Actual: "The disk /dev/vda is 20G in size. It's a VirtIO Block device..."
```
The model describes the disk instead of executing the partitioning command.

### Example: Continue Flow
```
User: "continue"
Expected: mount /dev/vda2 /mnt && mkdir -p /mnt/boot/efi ...
Actual: "$ mount /dev/vda1 /mnt && mount /dev/vda2 /mnt/home..."
```
The model outputs the command as text, not as a tool call.

## Recommendation

**Keep the LoRA training infrastructure.** A fine-tuned adapter will teach the model:

1. **Correct command selection** - `lsblk` for listing disks, `sgdisk` for partitioning, etc.
2. **Workflow state machine** - Understanding that confirmations trigger actions
3. **Consistent tool call usage** - Always use `<tool_call>` format, never inline commands in text

### Expected Improvement with LoRA

Based on the training data structure and the model's existing capabilities:
- Type accuracy: 49% → 85%+
- Command exact match: 0% → 60%+
- Command partial match: 100% → 100% (already good)

The training data already exists in `training/` and `conversations/` directories. The model fundamentally works; it just needs domain-specific knowledge.

## Test Command

```bash
cd crates/installer/python
python test_model.py --model ../../../vendor/models/SmolLM3-3B -n 100
```

---

## LoRA Training (In Progress)

**Started:** 2026-01-16
**Configuration:**
- Base model: SmolLM3-3B (4-bit quantized)
- LoRA rank: 32, alpha: 64
- Learning rate: 1e-4 with cosine decay
- Epochs: 5
- Dataset: 7,716 examples (6,944 train / 772 eval)
  - Original augmented data: 6,088 examples
  - Targeted weakness data: 1,628 examples (generated by `generate_targeted_data.py`)

**Targeted Improvements:**
1. Command selection (lsblk vs df -h)
2. Contextual workflow understanding (confirmations trigger actions)
3. Tool call format consistency (`<tool_call>` vs inline text)

**Training Progress:**
- Step 50: loss=1.399, lr=1.13e-05
- (training in progress...)
